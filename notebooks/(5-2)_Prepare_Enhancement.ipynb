{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**요약**\n",
    "- 사전학습된 OneFormer로부터 `test_image`에 대하여 예측을 합니다.\n",
    "- 코드는 OneFormer [공식 데모 코드](https://colab.research.google.com/github/SHI-Labs/OneFormer/blob/main/colab/oneformer_colab.ipynb#scrollTo=xX8TLytOVal8)로부터 작성되었습니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Inputs:**\n",
    "- `dir_data`: 데이터가 있는 디렉토리\n",
    "- `dir_save`: 예측 결과들이 저장될 디렉토리\n",
    "\n",
    "<br>\n",
    "\n",
    "**Outputs**:\n",
    "- f`{dir_save}/ade/ade_din_pa_pa.pickle: Ade-20k dinat 모델의 panoptic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/ade/ade_din_se_pa.pickle: Ade-20k dinat 모델의 semantic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/ade/ade_swin_pa_pa.pickle: Ade-20k swin 모델의 panoptic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/ade/ade_swin_se_pa.pickle: Ade-20k swin 모델의 semantic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/co/co_din_pa_pa.pickle: CoCo dinat 모델의 panoptic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/co/co_din_se_pa.pickle: CoCo dinat 모델의 semantic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/co/co_swin_pa_pa.pickle: CoCo swin 모델의 panoptic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/co/co_swin_sa_pa.pickle: CoCo swin 모델의 semantic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/city/city_din_pa_pa.pickle: CoCo dinat 모델의 panoptic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/city/city_din_se_pa.pickle: CoCo dinat 모델의 semantic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/city/city_swin_pa_pa.pickle: CoCo swin 모델의 panoptic task의 panoptic segmentation 결과\n",
    "- f`{dir_save}/city/city_swin_sa_pa.pickle: CoCo swin 모델의 semantic task의 panoptic segmentation 결과\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = '../data'\n",
    "dir_save = '../outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongjin/miniconda3/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.13.0\n",
      "1\n",
      "NVIDIA A100-SXM4-40GB MIG 7g.40gb\n",
      "/home/dongjin/projects/da/notebooks/OneFormer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "%cd ./OneFormer/\n",
    "import sys, os, distutils.core\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "#@title 3. Import Libraries and other Utilities\n",
    "######\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "setup_logger(name=\"oneformer\")\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import imutils\n",
    "\n",
    "# Import detectron2 utilities\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from detectron2.data import MetadataCatalog\n",
    "from demo.defaults import DefaultPredictor\n",
    "from demo.visualizer import Visualizer, ColorMode\n",
    "\n",
    "\n",
    "# import OneFormer Project\n",
    "from oneformer import (\n",
    "    add_oneformer_config,\n",
    "    add_common_config,\n",
    "    add_swin_config,\n",
    "    add_dinat_config,\n",
    "    add_convnext_config,\n",
    ")\n",
    "\n",
    "######\n",
    "#@title 4. Define helper functions\n",
    "######\n",
    "cpu_device = torch.device(\"cpu\")###############\n",
    "gpu_device = torch.device(\"cuda\")\n",
    "SWIN_CFG_DICT = {\"cityscapes\": \"configs/cityscapes/oneformer_swin_large_IN21k_384_bs16_90k.yaml\",\n",
    "            \"coco\": \"configs/coco/oneformer_swin_large_IN21k_384_bs16_100ep.yaml\",\n",
    "            \"ade20k\": \"configs/ade20k/oneformer_swin_large_IN21k_384_bs16_160k.yaml\",}\n",
    "\n",
    "DINAT_CFG_DICT = {\"cityscapes\": \"configs/cityscapes/oneformer_dinat_large_bs16_90k.yaml\",\n",
    "            \"coco\": \"configs/coco/oneformer_dinat_large_bs16_100ep.yaml\",\n",
    "            \"ade20k\": \"configs/ade20k/oneformer_dinat_large_IN21k_384_bs16_160k.yaml\",}\n",
    "\n",
    "def setup_cfg(dataset, model_path, use_swin):\n",
    "    # load config from file and command-line arguments\n",
    "    cfg = get_cfg()\n",
    "    add_deeplab_config(cfg)\n",
    "    add_common_config(cfg)\n",
    "    add_swin_config(cfg)\n",
    "    add_dinat_config(cfg)\n",
    "    add_convnext_config(cfg)\n",
    "    add_oneformer_config(cfg)\n",
    "    if use_swin:\n",
    "        cfg_path = SWIN_CFG_DICT[dataset]\n",
    "    else:\n",
    "        cfg_path = DINAT_CFG_DICT[dataset]\n",
    "    cfg.merge_from_file(cfg_path)\n",
    "    cfg.MODEL.DEVICE = 'cuda'###############\n",
    "    # cfg.MODEL.DEVICE = 'cuda'\n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "    cfg.freeze()\n",
    "    return cfg\n",
    "\n",
    "def setup_modules(dataset, model_path, use_swin):\n",
    "    cfg = setup_cfg(dataset, model_path, use_swin)\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    metadata = MetadataCatalog.get(\n",
    "        cfg.DATASETS.TEST_PANOPTIC[0] if len(cfg.DATASETS.TEST_PANOPTIC) else \"__unused\"\n",
    "    )\n",
    "    if 'cityscapes_fine_sem_seg_val' in cfg.DATASETS.TEST_PANOPTIC[0]:\n",
    "        from cityscapesscripts.helpers.labels import labels\n",
    "        stuff_colors = [k.color for k in labels if k.trainId != 255]\n",
    "        metadata = metadata.set(stuff_colors=stuff_colors)\n",
    "    \n",
    "    return predictor, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ade20k Data Oneformer pretrained model로 부터 test_image inference pickle 파일 만들기\n",
    "\n",
    "- ade_din_pa_pa.pickle\n",
    "- ade_din_se_pa.pickle\n",
    "- ade_swin_pa_pa.pickle\n",
    "- ade_swin_se_pa.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config configs/ade20k/oneformer_dinat_large_IN21k_384_bs16_160k.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "Loading config configs/ade20k/Base-ADE20K-UnifiedSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/05 10:11:10 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from 250_16_dinat_l_oneformer_ade20k_160k.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mtext_encoder.positional_embedding\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.ln_final.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.token_embedding.weight\u001b[0m\n",
      "  \u001b[35mtext_projector.layers.0.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_projector.layers.1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mprompt_ctx.weight\u001b[0m\n",
      "Loading config configs/ade20k/oneformer_swin_large_IN21k_384_bs16_160k.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "Loading config configs/ade20k/Base-ADE20K-UnifiedSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "/home/dongjin/miniconda3/envs/torch/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975312/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/05 10:11:24 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from 250_16_swin_l_oneformer_ade20k_160k.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mtext_encoder.positional_embedding\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.0.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.1.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.2.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.3.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.4.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.ln_1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.mlp.c_fc.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.mlp.c_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.transformer.resblocks.5.ln_2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.ln_final.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_encoder.token_embedding.weight\u001b[0m\n",
      "  \u001b[35mtext_projector.layers.0.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtext_projector.layers.1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mprompt_ctx.weight\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "use_swin0 = False\n",
    "predictor_ade_din, metadata_ade_din = setup_modules(\"ade20k\", \"250_16_dinat_l_oneformer_ade20k_160k.pth\", use_swin0)\n",
    "\n",
    "use_swin1 = True\n",
    "predictor_ade_swin, metadata_ade_swin = setup_modules(\"ade20k\", \"250_16_swin_l_oneformer_ade20k_160k.pth\", use_swin1)\n",
    "\n",
    "os.makedirs(os.path.join('../', dir_save, 'ade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "## ade_din_pa_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name = 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_ade_din(img, \"panoptic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/ade/ade_din_pa_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2194/2194 [13:23<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "## ade_din_se_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name = 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_ade_din(img, \"semantic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/ade/ade_din_se_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2194/2194 [12:58<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "## ade_swin_pa_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name = 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_ade_swin(img, \"panoptic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/ade/ade_swin_pa_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2194/2194 [13:36<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "## ade_swin_se_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name= 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_ade_swin(img, \"semantic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/ade/ade_swin_se_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coco Data Oneformer pretrained model로 부터 test_image inference pickle 파일 만들기\n",
    "\n",
    "- co_din_pa_pa.pickle\n",
    "- co_din_se_pa.pickle\n",
    "- co_swin_pa_pa.pickle\n",
    "- co_swin_se_pa.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_swin0 = False\n",
    "predictor_co_din, metadata_co_din = setup_modules(\"coco\", \"150_16_dinat_l_oneformer_coco_100ep.pth\", use_swin0)\n",
    "\n",
    "use_swin1 = True\n",
    "predictor_co_swin, metadata_co_swin = setup_modules(\"coco\", \"150_16_swin_l_oneformer_coco_100ep.pth\", use_swin1)\n",
    "\n",
    "os.makedirs(os.path.join('../', dir_save, 'co'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## co_din_pa_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name= 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_co_din(img, \"panoptic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/co/co_din_pa_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## co_din_se_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name = 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_co_din(img, \"semantic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/co/co_din_se_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## co_swin_pa_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name = 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_co_swin(img, \"panoptic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/co/co_swin_pa_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## co_swin_se_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name = 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_co_swin(img, \"semantic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/co/co_swin_se_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cityscape Data Oneformer pretrained model로 부터 test_image inference pickle 파일 만들기\n",
    "\n",
    "- city_din_pa_pa.pickle\n",
    "- city_din_se_pa.pickle\n",
    "- city_swin_pa_pa.pickle\n",
    "- city_swin_se_pa.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_swin0 = False\n",
    "predictor_city_din, metadata_city_din = setup_modules(\"cityscapes\", \"250_16_dinat_l_oneformer_cityscapes_90k.pth\", use_swin0)\n",
    "\n",
    "use_swin1 = True\n",
    "predictor_city_swin, metadata_city_swin = setup_modules(\"cityscapes\", \"250_16_swin_l_oneformer_cityscapes_90k.pth\", use_swin1)\n",
    "\n",
    "os.makedirs(os.path.join('../', dir_save, 'city'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## city_din_pa_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name= 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_city_din(img, \"panoptic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/city/city_din_pa_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## city_din_se_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name= 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_city_din(img, \"semantic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/city/city_din_se_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## city_swin_pa_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name= 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_city_swin(img, \"panoptic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/city/city_swin_pa_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## city_swin_se_pa.picle 만들기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').setLevel(logging.ERROR) # 이상한 문구 뜨는거 끄는 것.\n",
    "\n",
    "result={}\n",
    "for ind in tqdm(range(1898)): \n",
    "    name= 'TEST_' + str(ind).zfill(4) + '.png'\n",
    "    test_img_path = os.path.join('../', dir_data, 'test_image', name)\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out1,out2 = predictor_city_swin(img, \"semantic\")['panoptic_seg']\n",
    "    result[ind]=(out1.cpu().numpy().astype(np.uint8),out2)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open(f'../{dir_save}/city/city_swin_se_pa.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
